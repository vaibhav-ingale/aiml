services:
  nginx:
    image: nginx:alpine
    container_name: nginx-proxy
    hostname: nginx-proxy
    restart: unless-stopped
    ports:
      - "80:80"
    volumes:
      - ./nginx.conf:/etc/nginx/nginx.conf:ro
      - ./index.html:/usr/share/nginx/html/index.html:ro
    depends_on:
      - spark-master
      - spark-worker-1
      - spark-worker-2
      - spark-worker-3
      - spark-history-server
      - jupyter
      - minio
    networks:
      - spark-network

  spark-master:
    image: apache/spark:4.0.1-python3
    container_name: spark-master
    hostname: spark-master
    restart: unless-stopped
    command: >
      bash -c "/opt/spark/bin/spark-class org.apache.spark.deploy.master.Master --host $${SPARK_MASTER_HOST} --port $${SPARK_MASTER_PORT} --webui-port $${SPARK_MASTER_WEBUI_PORT}"
    environment:
      - SPARK_MASTER_HOST=spark-master
      - SPARK_MASTER_PORT=7077
      - SPARK_MASTER_WEBUI_PORT=8080
      - SPARK_LOCAL_DIRS=/tmp/spark-local
      - SPARK_LOG_DIR=/tmp/spark-logs
      - PYSPARK_PYTHON=/usr/bin/python3.10
      - PYSPARK_DRIVER_PYTHON=/usr/bin/python3.10
    ports:
      - "7077:7077" # Spark Master Port (internal communication)
    volumes:
      - ./data:/opt/spark/work-dir/data
      - ./notebooks:/opt/spark/work-dir/notebooks
      - spark-logs:/tmp/spark-logs
      - ./data:/home/jovyan/data
      - ./notebooks:/home/jovyan/work      
    networks:
      - spark-network
    healthcheck:
      test: [ "CMD", "curl", "-f", "http://localhost:8080" ]
      interval: 30s
      timeout: 10s
      retries: 3

  spark-worker-1:
    image: apache/spark:4.0.1-python3
    container_name: spark-worker-1
    hostname: spark-worker-1.lab
    restart: unless-stopped
    command: >
      bash -c "/opt/spark/bin/spark-class org.apache.spark.deploy.worker.Worker $${SPARK_MASTER_URL} --cores $${SPARK_WORKER_CORES} --memory $${SPARK_WORKER_MEMORY} --webui-port $${SPARK_WORKER_WEBUI_PORT}"
    environment:
      - SPARK_MASTER_URL=spark://spark-master:7077
      - SPARK_WORKER_CORES=2
      - SPARK_WORKER_MEMORY=2g
      - SPARK_WORKER_WEBUI_PORT=8081
      - SPARK_LOCAL_DIRS=/tmp/spark-local
      - SPARK_LOG_DIR=/tmp/spark-logs
      - PYSPARK_PYTHON=/usr/bin/python3.10
      - PYSPARK_DRIVER_PYTHON=/usr/bin/python3.10
      - SPARK_PUBLIC_DNS=spark-worker-1.lab
      - SPARK_LOCAL_HOSTNAME=spark-worker-1.lab

    # Web UI accessed through nginx
    depends_on:
      - spark-master
    volumes:
      - ./data:/opt/spark/work-dir/data
      - ./notebooks:/opt/spark/work-dir/notebooks
      - spark-logs:/tmp/spark-logs
      - ./data:/home/jovyan/data
      - ./notebooks:/home/jovyan/work      

    networks:
      - spark-network
    healthcheck:
      test: [ "CMD", "curl", "-f", "http://localhost:8081" ]
      interval: 30s
      timeout: 10s
      retries: 3
  
  spark-worker-2:
    image: apache/spark:4.0.1-python3
    container_name: spark-worker-2
    hostname: spark-worker-2.lab
    restart: unless-stopped
    command: >
      bash -c "/opt/spark/bin/spark-class org.apache.spark.deploy.worker.Worker $${SPARK_MASTER_URL} --cores $${SPARK_WORKER_CORES} --memory $${SPARK_WORKER_MEMORY} --webui-port $${SPARK_WORKER_WEBUI_PORT}"
    environment:
      - SPARK_MASTER_URL=spark://spark-master:7077
      - SPARK_WORKER_CORES=2
      - SPARK_WORKER_MEMORY=2g
      - SPARK_WORKER_WEBUI_PORT=8082
      - SPARK_LOCAL_DIRS=/tmp/spark-local
      - SPARK_LOG_DIR=/tmp/spark-logs
      - PYSPARK_PYTHON=/usr/bin/python3.10
      - PYSPARK_DRIVER_PYTHON=/usr/bin/python3.10
      - SPARK_PUBLIC_DNS=spark-worker-2.lab
      - SPARK_LOCAL_HOSTNAME=spark-worker-2.lab

    # Web UI accessed through nginx
    depends_on:
      - spark-master
    volumes:
      - ./data:/opt/spark/work-dir/data
      - ./notebooks:/opt/spark/work-dir/notebooks
      - spark-logs:/tmp/spark-logs
      - ./data:/home/jovyan/data
      - ./notebooks:/home/jovyan/work      

    networks:
      - spark-network
    healthcheck:
      test: [ "CMD", "curl", "-f", "http://localhost:8082" ]
      interval: 30s
      timeout: 10s
      retries: 3
  
  spark-worker-3:
    image: apache/spark:4.0.1-python3
    container_name: spark-worker-3
    hostname: spark-worker-3.lab
    restart: unless-stopped
    command: >
      bash -c "/opt/spark/bin/spark-class org.apache.spark.deploy.worker.Worker $${SPARK_MASTER_URL} --cores $${SPARK_WORKER_CORES} --memory $${SPARK_WORKER_MEMORY} --webui-port $${SPARK_WORKER_WEBUI_PORT}"
    environment:
      - SPARK_MASTER_URL=spark://spark-master:7077
      - SPARK_WORKER_CORES=2
      - SPARK_WORKER_MEMORY=2g
      - SPARK_WORKER_WEBUI_PORT=8083
      - SPARK_LOCAL_DIRS=/tmp/spark-local
      - SPARK_LOG_DIR=/tmp/spark-logs
      - PYSPARK_PYTHON=/usr/bin/python3.10
      - PYSPARK_DRIVER_PYTHON=/usr/bin/python3.10
      - SPARK_PUBLIC_DNS=spark-worker-3.lab
      - SPARK_LOCAL_HOSTNAME=spark-worker-3.lab

    # Web UI accessed through nginx
    depends_on:
      - spark-master
    volumes:
      - ./data:/opt/spark/work-dir/data
      - ./notebooks:/opt/spark/work-dir/notebooks
      - spark-logs:/tmp/spark-logs
      - ./data:/home/jovyan/data
      - ./notebooks:/home/jovyan/work      

    networks:
      - spark-network
    healthcheck:
      test: [ "CMD", "curl", "-f", "http://localhost:8083" ]
      interval: 30s
      timeout: 10s
      retries: 3
  
  spark-history-server:
    image: apache/spark:4.0.1-python3
    container_name: spark-history-server
    hostname: spark-history-server
    restart: unless-stopped
    command: >
      bash -c "/opt/spark/bin/spark-class org.apache.spark.deploy.history.HistoryServer"
    environment:
      - SPARK_HISTORY_OPTS=-Dspark.history.fs.logDirectory=file:///tmp/spark-logs
      - SPARK_HISTORY_PORT=18080
      - PYSPARK_PYTHON=/usr/bin/python3.10
      - PYSPARK_DRIVER_PYTHON=/usr/bin/python3.10

    # Web UI accessed through nginx
    volumes:
      - spark-logs:/tmp/spark-logs
    networks:
      - spark-network
    depends_on:
      - spark-master
    healthcheck:
      test: [ "CMD", "curl", "-f", "http://localhost:18080" ]
      interval: 30s
      timeout: 10s
      retries: 3

  jupyter:
    build:
      context: .
      dockerfile: Dockerfile.jupyter
    container_name: spark-jupyter.lab
    hostname: spark-jupyter.lab
    restart: unless-stopped
    environment:
      - SPARK_MASTER=spark://spark-master:7077
      - JUPYTER_ENABLE_LAB=yes
      - JUPYTER_TOKEN=spark123
      - SPARK_HOME=/opt/spark
      - PYTHONPATH=/opt/spark/python:/opt/spark/python/lib/py4j-*.zip
      - PYSPARK_PYTHON=/usr/bin/python3.10
      - PYSPARK_DRIVER_PYTHON=/usr/bin/python3.10
    ports:
      - "4040-4050:4040-4050" # Spark UI for Jupyter (internal)
      
  
    volumes:
      - ./notebooks:/home/jovyan/work
      - ./data:/home/jovyan/data
      - ./spark-defaults.conf:/opt/spark/conf/spark-defaults.conf
    depends_on:
      - spark-master
      - spark-worker-1
      - spark-worker-2
      - spark-worker-3
    networks:
      - spark-network

  minio:
    image:  quay.io/minio/minio:latest
    container_name: spark-minio
    hostname: spark-minio
    restart: unless-stopped
    environment:
      - MINIO_ROOT_USER=minioadmin
      - MINIO_ROOT_PASSWORD=minioadmin123
      - MINIO_BROWSER_REDIRECT_URL=http://minio-console.lab
    command: server /data --console-address ":9001"
    # API and Console accessed through nginx
    volumes:
      - ./minio-data:/data
    networks:
      - spark-network
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:9000/minio/health/live"]
      interval: 30s
      timeout: 20s
      retries: 3

networks:
  spark-network:
    driver: bridge

volumes:
  spark-logs:
  spark-data:

