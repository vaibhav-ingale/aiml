# Spark master (standalone cluster in your case)
spark.master                     spark://spark-master:7077

# Driver memory (example 1 GB)
# spark.driver.memory              1g

# Executor memory
# spark.executor.memory            1g

# Executor cores
# spark.executor.cores             1

# Max total cores across all executors (important in standalone mode)
# spark.cores.max                  2

# AWS S3A JAR files (will be downloaded during Docker build)
spark.jars                               /opt/spark/jars/hadoop-aws-3.3.6.jar,/opt/spark/jars/aws-java-sdk-bundle-1.12.565.jar

# S3A Configuration for MinIO
spark.hadoop.fs.s3a.endpoint            http://spark-minio:9000
spark.hadoop.fs.s3a.access.key          minioadmin
spark.hadoop.fs.s3a.secret.key          minioadmin123
spark.hadoop.fs.s3a.path.style.access   true
spark.hadoop.fs.s3a.impl                org.apache.hadoop.fs.s3a.S3AFileSystem
spark.hadoop.fs.s3a.connection.ssl.enabled  false
spark.hadoop.fs.s3a.attempts.maximum    3
spark.hadoop.fs.s3a.connection.establish.timeout  5000
spark.hadoop.fs.s3a.connection.timeout  10000
spark.hadoop.fs.s3a.connection.request.timeout  60000
spark.hadoop.fs.s3a.socket.recv.buffer  65536
spark.hadoop.fs.s3a.socket.send.buffer  65536
spark.hadoop.fs.s3a.retry.interval      1000
spark.hadoop.fs.s3a.retry.limit         3
spark.hadoop.fs.s3a.multipart.size      104857600
spark.hadoop.fs.s3a.fast.upload         true
spark.hadoop.fs.s3a.block.size          67108864